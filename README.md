# Manuscript Workflow System This repository contains the codebase and documentation for a proprietary workflow designed for the generation, expansion, and management of novel-length narratives. The system leverages a combination of a structured database (Airtable), custom Python scripts for data processing and automation, AI-driven content generation and analysis (facilitated by an AI agent like Manus), and iterative user guidance through prompts and feedback. ## Overview The core idea is to create a yet framework that can support the creation of complex narratives from initial concept to a complete manuscript, allowing for detailed tracking, targeted development, and data-informed creative decisions. Refer to `proprietary_novel_generation_workflow.md` for a detailed breakdown of the system architecture, components, and workflow steps. ## Components * **Airtable**: Central narrative database. Schema details in `novel_project_airtable_schema.md`.
* **Python Scripts**: Located in the root of this repository. These scripts handle tasks such as text segmentation, Airtable uploading/fetching, chapter, and analytics generation.
* **Workflow Documentation**: `proprietary_novel_generation_workflow.md`. ## Setup 1. **Airtable**: * Set up an Airtable base according to the schema defined in `novel_project_airtable_schema.md`. * Obtain your Airtable API Key and Base ID.
2. **Python Environment**: * Ensure Python 3.11+ is installed. * Install necessary Python libraries (e.g., `requests`, `python-dotenv`). A `requirements.txt` could be added in the future.
3. **Environment Variables**: The Python scripts ( `fetch_airtable_data.py` and `airtable_uploader.py`) expect the following environment variables to be set, or you can hardcode them into the scripts (not recommended for sensitive keys): * `AIRTABLE_API_KEY`: Your Airtable Personal Access Token. * `AIRTABLE_BASE_ID`: The ID of your Airtable base for the novel project. * `AIRTABLE_CHAPTERS_TABLE_ID`: The ID of the "Chapters" table in your base. * `AIRTABLE_SEGMENTS_TABLE_ID`: The ID of the "Text Segments" table in your base. ## Scripts * `segmenter_script.py`: Processes initial manuscript text into segments.
* `airtable_uploader.py`: Uploads segmented text to Airtable.
* `fetch_airtable_data.py`: Fetches data from Airtable to local JSON files.
* `extract_options_script.py`: Manages options for multi-select fields in Airtable.
* `chapter_assembler.py`: Assembles chapter text from Airtable segments.
* `generate_analytics_script.py`: Generates quantitative analytics from Airtable data. ## Usage Refer to the individual scripts and the main workflow document for detailed usage instructions. The system is designed to be orchestrated by an AI agent (like Manus) or run by a user familiar with the components. ## Future Development This system is intended for ongoing development. Future enhancements may include: * Enhanced NLP for automated tagging.
* Direct LLM-Airtable integration.
* A custom web-based dashboard.
* Prompt library management.
* Support for multi-novel management. This project was initiated by Patrick Somerville and developed with the assistance of the Manus AI agent.